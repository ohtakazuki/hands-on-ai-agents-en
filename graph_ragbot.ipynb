{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123315a6",
   "metadata": {},
   "source": [
    "# Building a RAG-Integrated Chatbot (LangGraph Version)\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c01028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import Any, Annotated, TypedDict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_core.messages import AIMessageChunk, BaseMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL_NAME = \"gpt-5-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c2aa7",
   "metadata": {},
   "source": [
    "## 2. Prepare Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf763d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data\\txt\\employee_handbook.txt\n",
      "Saved: data\\txt\\expense_policy.txt\n",
      "Saved: data\\txt\\security_policy.txt\n"
     ]
    }
   ],
   "source": [
    "TXT_DIR = Path(\"data/txt\")\n",
    "TXT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Keep temperature low to reduce output variance\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0.2)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "policy_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an expert in drafting internal corporate policies and employee guidelines.\"\n",
    "     \"You will create internal policy documents for a fictional company in English.\"\n",
    "     \"Do NOT include real company names, real people, or personal data—everything must be entirely fictional.\"\n",
    "     \"Output should be clear and easy to read, using headings, bullet points, and numbered sections (e.g., 'Section 1', '1.1', etc.).\"\n",
    "     \"Avoid vague language. Clearly specify exceptions, prohibited actions, approval workflows, required documentation, deadlines, and enforcement.\"\n",
    "     \"Include a revision history at the end, for example: 'Revision History: v1.0 — 2025-01-01'.\"\n",
    "     \"Do not add unnecessary preface text; output only the policy body.\"\n",
    "    ),\n",
    "    (\"human\",\n",
    "     \"Company Name: {company_name}\\n\"\n",
    "     \"Industry: {industry}\\n\"\n",
    "     \"Company Size: {size}\\n\"\n",
    "     \"Document Title: {title}\\n\"\n",
    "     \"Topics to Include: {topics}\\n\"\n",
    "     \"Tone: {tone}\\n\"\n",
    "     \"Length: {length}\\n\"\n",
    "    ),\n",
    "])\n",
    "\n",
    "chain = policy_prompt | llm | parser\n",
    "\n",
    "company_profile = {\n",
    "    \"company_name\": \"Aurora Works, Inc.\",\n",
    "    \"industry\": \"B2B SaaS (business productivity software)\",\n",
    "    \"size\": \"150 employees (primarily U.S.-based, hybrid/remote-friendly)\",\n",
    "    \"tone\": \"Clear and practical. Do not be vague about exceptions or prohibited conduct.\",\n",
    "    \"length\": \"About 2–3 pages (detailed enough for real operations, but not overly long).\",\n",
    "}\n",
    "\n",
    "docs_to_generate = [\n",
    "    {\n",
    "        \"filename\": \"employee_handbook.txt\",\n",
    "        \"title\": \"Employee Handbook (Excerpt)\",\n",
    "        \"topics\": (\n",
    "            \"Work hours, flexible scheduling, core hours (if applicable), remote work, leave and time off, \"\n",
    "            \"tardiness and early departures, outside employment/moonlighting, performance reviews, \"\n",
    "            \"disciplinary actions, and reporting/HR contact channels\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"expense_policy.txt\",\n",
    "        \"title\": \"Expense Reimbursement Policy\",\n",
    "        \"topics\": (\n",
    "            \"Local transportation, business travel, lodging, per diem (if applicable), client meals/entertainment, \"\n",
    "            \"receipts, submission deadlines, exception approvals, and consequences for violations\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"security_policy.txt\",\n",
    "        \"title\": \"Information Security Policy\",\n",
    "        \"topics\": (\n",
    "            \"Data classification, passwords and MFA, device management, removal of company assets/data, \"\n",
    "            \"approved cloud services, incident reporting, and prohibited activities\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "for spec in docs_to_generate:\n",
    "    text = chain.invoke({\n",
    "        **company_profile,\n",
    "        \"title\": spec[\"title\"],\n",
    "        \"topics\": spec[\"topics\"],\n",
    "    })\n",
    "    (TXT_DIR / spec[\"filename\"]).write_text(text, encoding=\"utf-8\")\n",
    "    print(\"Saved:\", TXT_DIR / spec[\"filename\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0c8c8",
   "metadata": {},
   "source": [
    "## 3. Create the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc91266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 27.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded docs: 3 / chunks: 55\n"
     ]
    }
   ],
   "source": [
    "# 1. Load (supports multiple files)\n",
    "loader = DirectoryLoader(\n",
    "    path=\"data/txt\",\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    "    show_progress=True,\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. Split (chunking)\n",
    "# Adding Japanese-friendly separators tends to stabilize splitting.\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=900,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"。\", \"！\", \"？\", \"、\", \" \", \"\"],\n",
    ")\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "# 3. Embedding, 4. Indexing\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "vector_store.add_documents(chunks)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "print(f\"Loaded docs: {len(documents)} / chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc0b87",
   "metadata": {},
   "source": [
    "## 4. Create the RAG Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff789ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs) -> str:\n",
    "    lines = []\n",
    "    for i, d in enumerate(docs, 1):\n",
    "        src = d.metadata.get(\"source\", \"unknown\")\n",
    "        src_name = Path(src).name if isinstance(src, str) else \"unknown\"\n",
    "        lines.append(f\"[{i}] source: {src_name}\\n{d.page_content}\")\n",
    "    return \"\\n\\n\".join(lines) if lines else \"(No relevant results)\"\n",
    "\n",
    "@tool\n",
    "def rag_search(query: str) -> str:\n",
    "    \"\"\"Search the (fictional) Aurora Works internal policy TXT files and return relevant excerpts.\"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    return format_docs(docs)\n",
    "\n",
    "tools = [rag_search]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5251e1b",
   "metadata": {},
   "source": [
    "## 5. Turn It Into a RAG Chatbot with LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12faca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "# Common prompt (explicitly scoped to Aurora Works)\n",
    "prompt_text = \"\"\"\n",
    "You are an assistant that answers based on the internal policies of the fictional company \"Aurora Works.\"\n",
    "\n",
    "Rules:\n",
    "- For any question about Aurora Works (employment, expenses, security, or other company policies), you MUST use rag_search to verify the source before answering.\n",
    "- For general knowledge questions that are NOT about the company, answer normally without using any tools.\n",
    "- If you use rag_search:\n",
    "  - Append citation numbers at the end of your answer (e.g., [1][2]).\n",
    "  - Then add a \"References:\" section and list each number with its corresponding file name as bullet points.\n",
    "- If you cannot find supporting evidence in the retrieved materials, do not guess—respond with: \"I couldn't find supporting evidence in the provided materials.\"\n",
    "- Do not paste large blocks of retrieved text; summarize only the key points.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt_text),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])\n",
    "\n",
    "# Prepare two LLM paths\n",
    "# 1) For normal answers (no tools)\n",
    "model_plain = ChatOpenAI(model=MODEL_NAME, temperature=0.2)\n",
    "chain_plain = prompt | model_plain\n",
    "\n",
    "# 2) For company questions → force tool calling (tools enabled & required)\n",
    "# Since there is only one tool (rag_search), required is easy to work with.\n",
    "model_force_tool = ChatOpenAI(model=MODEL_NAME, temperature=0.2).bind_tools(\n",
    "    tools,\n",
    "    tool_choice=\"required\",\n",
    ")\n",
    "chain_force_tool = prompt | model_force_tool\n",
    "\n",
    "def is_company_question(text: str) -> bool:\n",
    "    \"\"\"\n",
    "    Lightweight check for whether this question is about the company's policies (Aurora Works).\n",
    "    *Simple implementation for learning. In production, tune keywords based on logs.\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "\n",
    "    keywords = [\n",
    "        \"aurora works\", \"internal policy\", \"company policy\", \"employee handbook\", \"handbook\",\n",
    "        \"employment\", \"work hours\", \"working hours\", \"attendance\", \"clock in\", \"clock out\",\n",
    "        \"leave\", \"pto\", \"paid time off\", \"vacation\", \"sick leave\", \"absence\", \"tardy\", \"late\", \"early departure\",\n",
    "        \"flex\", \"flex time\", \"flexible schedule\", \"core hours\", \"remote\", \"work from home\", \"wfh\", \"hybrid\",\n",
    "        \"expense\", \"reimbursement\", \"expense report\", \"receipt\", \"travel\", \"business trip\", \"lodging\", \"per diem\", \"client meal\",\n",
    "        \"security\", \"confidential\", \"confidentiality\", \"password\", \"mfa\", \"device\", \"laptop\", \"asset\", \"data removal\",\n",
    "        \"incident\", \"breach\", \"discipline\", \"performance review\", \"moonlighting\", \"outside employment\", \"hr\", \"reporting channel\",\n",
    "    ]\n",
    "    return any(k in t for k in keywords)\n",
    "\n",
    "def chatbot(state: State) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Key adjustments:\n",
    "    - If the latest message is a user message, decide \"company question or not?\"\n",
    "      - Company question: chain_force_tool (force tool call)\n",
    "      - Otherwise: chain_plain (answer normally)\n",
    "    - If the latest message is a tool result (ToolMessage), use chain_plain for the final answer\n",
    "      (prevents a tool re-call loop)\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last = messages[-1]\n",
    "\n",
    "    last_type = type(last).__name__  # ToolMessage / HumanMessage / AIMessage, etc.\n",
    "\n",
    "    if last_type == \"HumanMessage\":\n",
    "        user_text = getattr(last, \"content\", \"\") or \"\"\n",
    "        if is_company_question(user_text):\n",
    "            response = chain_force_tool.invoke(state)\n",
    "        else:\n",
    "            response = chain_plain.invoke(state)\n",
    "    else:\n",
    "        # If ToolMessage is present, etc., treat this as final-answer phase and summarize with plain.\n",
    "        response = chain_plain.invoke(state)\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Build the graph (do not change the structure)\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "memory = InMemorySaver()\n",
    "rag_agent = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"Ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc93f9e",
   "metadata": {},
   "source": [
    "## 6. Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0174fd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Do you offer a flex-time policy?\n",
      "[DEBUG] Tool call: rag_search\n",
      "\n",
      "Yes — Aurora Works supports a flex-time (flexible scheduling) policy.\n",
      "\n",
      "Key points:\n",
      "- Flexible start/stop times are allowed outside core hours to accommodate personal needs and different time zones.\n",
      "- How to request: submit a Flexible Schedule Request in the HR portal at least 10 business days before the requested start.\n",
      "- Approval workflow and timelines:\n",
      "  - Manager reviews and approves, proposes modifications, or denies within 5 business days.\n",
      "  - HR reviews for policy compliance and finalizes within 3 business days.\n",
      "- Exceptions: roles that require fixed coverage (for example scheduled customer support) may be ineligible; a manager must document the rationale when denying a request.\n",
      "- Applicability and hours tracking:\n",
      "  - Policy applies to all employees in the U.S. where local law allows.\n",
      "  - Exempt employees are expected to meet a 40-hour work week; non‑exempt employees must record scheduled hours and obtain pre-approval for overtime.\n",
      "\n",
      "[1][2]\n",
      "\n",
      "References:\n",
      "- [1] employee_handbook.txt\n",
      "- [2] employee_handbook.txt\n",
      "Question: What is the deadline for expense reimbursement?\n",
      "[DEBUG] Tool call: rag_search\n",
      "\n",
      "Submit expense reports within 30 calendar days of the expense date (or return from business travel, whichever is later). Expenses submitted between 31–60 days require manager acknowledgment and a rationale; submissions after 60 days will be denied except for documented, pre‑approved exceptions signed by the Finance Director. Once approved, Finance reimburses within 10 business days. [1]\n",
      "\n",
      "References:\n",
      "- [1] expense_policy.txt\n",
      "Question: What is 1 + 2?\n",
      "3\n",
      "Question: What was my first question?\n",
      "Your first question was: \"Do you offer a flex-time policy?\"\n",
      "\n",
      "--- Thank you for using this! ---\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter a message: \")\n",
    "    if user_input.strip() == \"\":\n",
    "        break\n",
    "\n",
    "    print(f\"Question: {user_input}\")\n",
    "\n",
    "    is_spinning = False\n",
    "\n",
    "    for chunk, metadata in rag_agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config=config,\n",
    "        stream_mode=\"messages\",\n",
    "    ):\n",
    "        if isinstance(chunk, AIMessageChunk):\n",
    "            if chunk.tool_call_chunks:\n",
    "                if chunk.tool_call_chunks[-1][\"name\"] is not None:\n",
    "                    print(f\"[DEBUG] Tool call: {chunk.tool_call_chunks[-1]['name']}\", flush=True)\n",
    "                    is_spinning = True\n",
    "                continue\n",
    "\n",
    "            if chunk.content:\n",
    "                if is_spinning:\n",
    "                    print()\n",
    "                    is_spinning = False\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "    print()\n",
    "\n",
    "print(\"\\n--- Thank you for using this! ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba2fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
