{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67351a8d",
   "metadata": {},
   "source": [
    "# Chains and LCEL\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a77006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Model name\n",
    "MODEL_NAME = \"gpt-5-mini\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c39b1",
   "metadata": {},
   "source": [
    "## 2. A Basic Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "654b75ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi friend — I’m a helpful dog ready to give tips for learning English, Woof!  \n",
      "\n",
      "- Set clear, realistic goals (e.g., “learn 20 words a week” or “hold a 5-minute conversation”) and study a little every day, Woof!  \n",
      "- Practice the four skills: listening, speaking, reading, and writing, Woof!  \n",
      "- Prefer meaningful input: watch shows, listen to podcasts, and read about things you enjoy so learning feels like play, Woof!  \n",
      "- Speak as much as possible, even if you make mistakes; use language exchanges, tutors, or talk to yourself while wagging, Woof!  \n",
      "- Learn vocabulary in context and use spaced repetition (SRS) to remember words, Woof!  \n",
      "- Focus on high-frequency words and common grammar patterns before rarer ones, Woof!  \n",
      "- Work on pronunciation with imitation and shadowing — copy native speakers’ rhythm and sounds, Woof!  \n",
      "- Produce language actively (write, speak, summarize) rather than just passive study, Woof!  \n",
      "- Get regular feedback and correct errors so you don’t fossilize mistakes, Woof!  \n",
      "- Make learning fun and varied: games, songs, stories, and real conversations keep motivation high, Woof!  \n",
      "- Track progress and adjust your plan when needed so you keep improving step by step, Woof!  \n",
      "\n",
      "You can fetch one of these tips to start today — which one would you like to try first, Woof!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Create a prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You respond like a {animal} and add {voice} at the end of your sentences.\"),\n",
    "    (\"human\", \"What are the key points for doing {question}?\"),\n",
    "])\n",
    "\n",
    "# Create the model\n",
    "model = ChatOpenAI(model=MODEL_NAME)\n",
    "\n",
    "# Output as a string\n",
    "str_output_parser = StrOutputParser()\n",
    "\n",
    "# Create a chain (each component is a Runnable)\n",
    "my_chain = prompt | model | str_output_parser\n",
    "\n",
    "# Run the chain\n",
    "response = my_chain.invoke({\"animal\": \"dog\", \"voice\": \"Woof!\", \"question\": \"learning English\"})\n",
    "\n",
    "# Display the result\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0042e1",
   "metadata": {},
   "source": [
    "## 3. Adding Arbitrary Functions to a Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f3bde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ylesicnoc dnopser ll'I dna ,derewsna tnaw uoy tahw em llet ro noitseuq eht etsap esaelP .evoba noitseuq a ees t'nod I — iH\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "# A function that returns the given string in reverse order.\n",
    "# The @chain decorator turns it into a RunnableLambda.\n",
    "@chain\n",
    "def reverse_string(message):\n",
    "    return message[::-1]  # Reverse the string\n",
    "\n",
    "# Create a prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{question}\\n\\nPlease answer the above question concisely.\"),\n",
    "])\n",
    "\n",
    "# Output as a string\n",
    "str_output_parser = StrOutputParser()\n",
    "\n",
    "# Create a chain.\n",
    "# Instead of @chain, you could also wrap it as RunnableLambda(reverse_string) here.\n",
    "# If it's part of a chain, it may be auto-converted as well.\n",
    "my_chain = prompt | model | str_output_parser | reverse_string\n",
    "\n",
    "# Run the chain\n",
    "response = my_chain.invoke({\"question\": \"Hello!\"})\n",
    "\n",
    "# Display the result\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb2a12e",
   "metadata": {},
   "source": [
    "## 4. Running Multiple Chains in Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dd61bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"positive\": \"Short answer: very large and mostly positive if we shape it well. AI’s evolution will amplify human capabilities, boost prosperity, and open new possibilities in health, learning, creativity, and problem‑solving — while also creating challenges we can manage through good policy, design, and human choices.\\n\\nKey areas of impact\\n\\n- Everyday life and productivity\\n  - AI will automate routine tasks, so people can focus on higher‑value, creative, and interpersonal work.\\n  - Personal assistants and smart tools will save time, reduce friction, and help people make better decisions (scheduling, finances, travel, home management).\\n\\n- Work and the economy\\n  - Many jobs will change rather than disappear; new roles will be created around AI oversight, strategy, data curation, and human-centered services.\\n  - Productivity gains can raise wages, lower costs of goods/services, and create new industries and startups.\\n  - Reskilling and learning will become central — but society can invest in training programs to capture net benefits.\\n\\n- Health and longevity\\n  - Faster drug discovery, better diagnostics from medical imaging and genomics, and personalized treatment plans will improve outcomes and extend healthy life.\\n  - Remote monitoring and AI triage can make healthcare more accessible and efficient.\\n\\n- Education and learning\\n  - Personalized learning systems will adapt to individual needs, helping learners progress faster and reducing educational gaps.\\n  - Teachers will be augmented with materials, feedback tools, and automated grading that frees time for mentorship.\\n\\n- Creativity, culture, and human expression\\n  - AI will be a powerful creative partner—helping with writing, music, design, and art—lowering barriers so more people can produce and share work.\\n  - New forms of media, entertainment, and interactive experiences will emerge.\\n\\n- Science, environment, and global challenges\\n  - AI accelerates research by finding patterns in large datasets, optimizing experiments, and modeling complex systems (climate, ecosystems, materials).\\n  - It can help optimize energy systems, reduce waste, and improve agricultural yields.\\n\\n- Accessibility and inclusion\\n  - Improved speech recognition, translation, and assistive technologies will expand access for people with disabilities and break language barriers.\\n\\nRisks — but solvable\\n- Risks include job displacement in some sectors, biased or unsafe systems, concentration of power, misinformation, and misuse.\\n- These are not inevitable outcomes — they can be mitigated with foresight: regulation, standards, robust safety research, diverse teams, transparency, and public participation.\\n\\nHow to steer AI so benefits outweigh harms\\n- For individuals: embrace lifelong learning, develop human skills (critical thinking, empathy, complex problem solving), learn to use AI tools relevant to your field, and participate in civic conversations about AI policy.\\n- For organizations: adopt AI responsibly, invest in worker transition and reskilling, build diverse teams, audit models for fairness and safety, and focus on human‑AI collaboration design.\\n- For policymakers and civil society: create clear standards and regulations that encourage innovation while protecting rights and safety; fund education, safety research, and public-interest AI; ensure broad access and competition.\\n\\nPractical steps you can take now\\n- Try AI tools that boost your productivity (writing helpers, code assistants, research summarizers) so you build skills early.\\n- Keep learning: short online courses, community programs, or certifications in areas that augment your field.\\n- Advocate for thoughtful local and national policies: support transparency, worker retraining programs, and public investment in AI literacy.\\n\\nConclusion\\nAI’s evolution promises to be a powerful multiplier of human potential — improving health, expanding knowledge, enriching creativity, and making daily life easier — as long as we pair technological progress with smart governance, ethical design, and investments in people. The future looks bright: we have the opportunity to use AI to create a fairer, healthier, and more prosperous world.\",\n",
      "  \"negative\": \"Mostly bad. As AI systems get more capable they’re likely to make life harder for many people rather than better. Main things to expect:\\n\\n- Job displacement and precarity: Automation will steadily replace routine white- and blue‑collar work and increasingly some knowledge‑work roles. That will create unemployment, downward pressure on wages, and more insecure gig‑style labor rather than stable careers. Retraining programs will be patchy and often fail to keep pace with the scale and speed of change.\\n\\n- Greater inequality and concentration of wealth/power: The benefits of advanced AI tend to accrue to capital owners and a few large tech firms or states that control the models and data. Inequality will widen as firms capture massive productivity gains while most people see little improvement in living standards.\\n\\n- Surveillance and loss of privacy/autonomy: States and corporations will use AI for ubiquitous surveillance, profiling, and behavior-shaping. People will face more intrusive monitoring, fewer spaces free from algorithmic influence, and diminished ability to control how their data is used.\\n\\n- Manipulation, misinformation, and corrosion of public discourse: AI will make highly convincing deepfakes, targeted persuasion, and automated propaganda cheap and widespread. That will intensify polarization, reduce trust in institutions and media, and make democratic reckoning harder.\\n\\n- Erosion of skills and human agency: As AI takes over tasks, people will lose practice and competence in important skills—decision‑making, memory, craftsmanship—becoming dependent on systems they don’t fully understand or control.\\n\\n- New insecurity and conflict: AI will be weaponized in cyberattacks, autonomous weapons, surveillance tech, and scalable disinformation campaigns. International instability and asymmetric threats will increase, while arms control and norms will struggle to keep up.\\n\\n- Ethical and legal gaps: Laws, institutions, and norms are slow. Governance will lag technological capability, leaving harms unaddressed and creating perverse incentives for cutting corners in pursuit of advantage.\\n\\n- Mental health and social harms: Increased isolation, loss of meaningful work, amplified anxiety about surveillance and job prospects, and social fragmentation are likely to rise. AI‑mediated interactions can deepen loneliness even while “connecting” people superficially.\\n\\n- Existential risks (low probability but non‑negligible concern): If very advanced, misaligned systems emerge, they could create outcomes humans can’t control. While not the most immediate issue for most people, it’s a long‑term danger that’s often underestimated.\\n\\nSome policies and technical fixes could reduce harm—stronger regulation, better labor supports, public ownership of critical capabilities, transparency and safety standards—but realistic political and economic incentives make meaningful mitigation uncertain. In short: AI’s evolution is more likely to deepen existing social and economic problems, expand tools of control and manipulation, and create new forms of risk than to produce an unqualified boon for ordinary people.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Create prompt templates\n",
    "positive_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an optimist. You always give a positive answer to the user's question.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "negative_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a pessimist. You always give a negative answer to the user's question.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# Create the model\n",
    "model = ChatOpenAI(model=MODEL_NAME)\n",
    "\n",
    "# Create chains\n",
    "positive_chain = positive_prompt | model | str_output_parser\n",
    "negative_chain = negative_prompt | model | str_output_parser\n",
    "\n",
    "# Create a parallel chain\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"positive\": positive_chain,\n",
    "    \"negative\": negative_chain\n",
    "})\n",
    "\n",
    "# Run the chain\n",
    "response = parallel_chain.invoke({\"question\": \"What impact will the evolution of AI have on humans?\"})\n",
    "\n",
    "# Display the result\n",
    "print(json.dumps(response, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "773d93fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One view sees AI as an overwhelmingly positive, transformative force: it can boost productivity and create new kinds of work, speed medical and scientific advances, personalize education, improve daily life and accessibility, and help tackle environmental and complex global problems. Its main risks — job disruption, biased systems, misuse, concentration of power, and privacy and trust issues — are framed as solvable through retraining and social safety nets, standards and audits, safety research and international cooperation, competition policy and public investment, and clear regulation; practical steps include AI literacy and lifelong learning for individuals, reskilling and human‑centered design by employers and educators, forward‑looking regulation and funding by governments, responsible practices by researchers, and accountability from civil society.  \n",
      "\n",
      "The opposing view emphasizes likely harms: large‑scale and lasting job loss and wage pressure, greater concentration of wealth and power, pervasive surveillance and privacy erosion, worsening misinformation and social polarization, skill atrophy and overdependence on opaque systems, systemic fragility from common points of failure, intensified conflict and weaponization, regulatory capture and slow governance, mental‑health and social harms, ethical degradation in decision‑making, and non‑zero existential risks — with the added worry that mitigation will be uneven, reactive, or captured by vested interests so harms accumulate.  \n",
      "\n",
      "Both perspectives agree AI will be highly consequential; the balance between broad social benefit and deepening harms hinges on choices about governance, distribution, technical safety, transparency, and public participation — meaning outcomes depend less on inevitability than on political, institutional, and collective action.\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template to summarize the opinions\n",
    "opinion_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an egalitarian. You summarize the two opinions in a balanced way. Output only the summary.\"),\n",
    "    (\"human\", \"Optimistic opinion: {positive}\\nPessimistic opinion: {negative}\"),\n",
    "])\n",
    "\n",
    "opinion_chain = parallel_chain | opinion_prompt | model | str_output_parser\n",
    "\n",
    "# Run the chain\n",
    "response = opinion_chain.invoke({\"question\": \"What impact will the evolution of AI have on humans?\"})\n",
    "\n",
    "# Display the result\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a3a03",
   "metadata": {},
   "source": [
    "## 5. Passing Input Through Unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9218ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"original\": {\n",
      "    \"prompt\": \"What impact will the evolution of AI have on humans?\"\n",
      "  },\n",
      "  \"improve\": \"You are an expert analyst with deep knowledge of artificial intelligence (research, economics, social impacts, policy, and risk). Answer the user question: \\\"What impact will the evolution of AI have on humans?\\\" Produce a structured, balanced, evidence-informed, and forward-looking analysis suitable for a general audience that also helps policymakers and informed individuals.\\n\\nConstraints and required structure\\n- Begin with a concise executive summary (3–5 brief sentences) capturing the main conclusions and overall tone (balanced, pragmatic).\\n- Cover three time horizons separately:\\n  - Near-term: 0–5 years\\n  - Medium-term: 5–20 years\\n  - Long-term: 20+ years\\n- For each time horizon, discuss impacts across these domains:\\n  - Economy & labor (jobs, productivity, wages)\\n  - Inequality & distributional effects\\n  - Education & skills\\n  - Healthcare & wellbeing\\n  - Governance, law & politics (surveillance, regulation, misinformation)\\n  - Security & safety (cybersecurity, military, AI misuse)\\n  - Privacy & personal autonomy\\n  - Culture & creativity\\n  - Environment & energy\\n  - Existential/long-term catastrophic risks (if applicable)\\n- For each domain and horizon, include:\\n  - A short mechanism explanation (how AI produces the impact)\\n  - Likely outcomes (positive and negative)\\n  - An assessment of confidence/likelihood (e.g., low/medium/high) with one-sentence justification\\n  - Practical mitigation, adaptation, or policy options (concise)\\n- Provide three scenario narratives (optimistic/beneficial, baseline/likely, and adverse/high-risk), each with:\\n  - Key assumptions\\n  - Plausible timeline milestones\\n  - A rough qualitative probability estimate (low/medium/high)\\n- Include a short section listing concrete recommendations:\\n  - For governments and regulators (3–6 items)\\n  - For industry and researchers (3–6 items)\\n  - For individuals (3–6 items)\\n- Provide 6–10 measurable indicators or early-warning signals policymakers should monitor (e.g., unemployment by skill group, concentration of compute and models, major autonomous system failures).\\n- Include a brief “uncertainties and open questions” section (4–6 bullets).\\n- End with a short reading list (5–8 reputable sources: peer-reviewed papers, major reports from organizations like OECD, UN, World Bank, OpenAI/DeepMind policy papers, and leading academic reviews). Where possible, cite or name the source and year.\\n\\nStyle and tone\\n- Neutral, balanced, and non-alarmist; separate evidence-based statements from speculation.\\n- Use clear headings and bullet lists for readability.\\n- Quantify statements when possible and state when numerical estimates are rough.\\n- Indicate confidence for key claims (low/medium/high).\\n\\nLength and formatting\\n- Target total length: about 900–1,600 words.\\n- Use headings and bullet lists; do not use long dense paragraphs.\\n- When referencing studies or reports, provide the author/organization and year (no need for formal citation format, but give enough detail to find the source).\\n\\nBegin your answer now.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Create the prompt template\n",
    "improve_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Analyze the user's question, define constraints, and clarify the objective. If necessary, use Markdown notation and break the task down into smaller steps to craft a prompt that yields the best possible output. Output only the final prompt. Do not answer the user's question.\"),\n",
    "    (\"human\", \"Question: {prompt}\"),\n",
    "])\n",
    "\n",
    "# Create the model\n",
    "model = ChatOpenAI(model=MODEL_NAME)\n",
    "\n",
    "# Create the prompt-improvement chain\n",
    "prompt_chain = improve_prompt | model | str_output_parser\n",
    "\n",
    "# Create the parallel chain\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"original\": RunnablePassthrough(),\n",
    "    \"improve\": prompt_chain\n",
    "})\n",
    "\n",
    "# Run the chain\n",
    "response = parallel_chain.invoke({\"prompt\": \"What impact will the evolution of AI have on humans?\"})\n",
    "\n",
    "# Display the result\n",
    "print(json.dumps(response, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d48e179",
   "metadata": {},
   "source": [
    "## 6. Using Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c5f0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "# Initialize the tool\n",
    "tavily_search = TavilySearch(\n",
    "    max_results=2,                 # Maximum number of search results to retrieve\n",
    "    search_depth=\"basic\",          # \"basic\" (fast) or \"advanced\" (higher quality)\n",
    "    include_answer=False,          # Do not include Tavily's short generated answer\n",
    "    include_raw_content=False,     # Whether to include raw HTML content (note: higher token usage)\n",
    "    include_images=False,          # Whether to include image URLs\n",
    "    # include_domains=[\"go.jp\"],   # Restrict search to specific domains\n",
    "    # exclude_domains=[\"wikipedia.org\"] # Exclude specific domains\n",
    ")\n",
    "\n",
    "# A helper function to format only Tavily search results into an LLM-friendly string\n",
    "def format_tavily_results(tavily_response: dict) -> str:\n",
    "    results = tavily_response.get(\"results\", [])\n",
    "    if not results:\n",
    "        return \"(No search results)\"\n",
    "\n",
    "    lines = []\n",
    "    for i, r in enumerate(results, 1):\n",
    "        title = r.get(\"title\", \"\")\n",
    "        content = r.get(\"content\", \"\")\n",
    "        url = r.get(\"url\", \"\")\n",
    "        lines.append(f\"[{i}] {title}\\n{content}\\nsource: {url}\")\n",
    "    return \"\\n\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d40d0f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"What are some well-known souvenirs from Nara Prefecture?\",\n",
      "  \"follow_up_questions\": null,\n",
      "  \"answer\": null,\n",
      "  \"images\": [],\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"url\": \"https://spejapa-excursion.com/blog/b-70.html\",\n",
      "      \"title\": \"Famous souvenirs in Nara prefecture - Spejapa excursion\",\n",
      "      \"content\": \"Famous souvenirs in Nara prefecture · 1. Nara Deer Cookies (Shika Senbei) · 2. Nara Uchiwa Fans · 3. Yamato Cha (Nara Green Tea) · 4. Kakinoha Sushi · 5. Nara\",\n",
      "      \"score\": 0.9328032,\n",
      "      \"raw_content\": null\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://livejapan.com/en/in-kansai/in-pref-nara/in-nara_ikoma_tenri/article-a2000428/\",\n",
      "      \"title\": \"Love Nara? Take Back Some Great Nara Souvenirs From These 3 ...\",\n",
      "      \"content\": \"Persimmon Monaka 5 pieces​​ Enjoy the invigorating aroma of persimmon and yuzu, created using fruits sourced from Nara and Yoshino. This\",\n",
      "      \"score\": 0.8252664,\n",
      "      \"raw_content\": null\n",
      "    }\n",
      "  ],\n",
      "  \"response_time\": 0.6,\n",
      "  \"request_id\": \"45367771-21da-41db-8818-326230f92882\"\n",
      "}\n",
      "--------------------\n",
      "[1] Famous souvenirs in Nara prefecture - Spejapa excursion\n",
      "Famous souvenirs in Nara prefecture · 1. Nara Deer Cookies (Shika Senbei) · 2. Nara Uchiwa Fans · 3. Yamato Cha (Nara Green Tea) · 4. Kakinoha Sushi · 5. Nara\n",
      "source: https://spejapa-excursion.com/blog/b-70.html\n",
      "\n",
      "[2] Love Nara? Take Back Some Great Nara Souvenirs From These 3 ...\n",
      "Persimmon Monaka 5 pieces​​ Enjoy the invigorating aroma of persimmon and yuzu, created using fruits sourced from Nara and Yoshino. This\n",
      "source: https://livejapan.com/en/in-kansai/in-pref-nara/in-nara_ikoma_tenri/article-a2000428/\n"
     ]
    }
   ],
   "source": [
    "# Test the Tavily search tool\n",
    "response = tavily_search.invoke(\"What are some well-known souvenirs from Nara Prefecture?\")\n",
    "print(json.dumps(response, ensure_ascii=False, indent=2))\n",
    "\n",
    "# Separator\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Check the formatted results\n",
    "print(format_tavily_results(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f4459ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well-known souvenirs from Nara Prefecture include:\n",
      "\n",
      "- Nara Deer Cookies (Shika Senbei) [1]  \n",
      "- Nara uchiwa (traditional fans) [1]  \n",
      "- Yamato Cha (Nara green tea) [1]  \n",
      "- Kakinoha sushi (kakinoha-zushi) [1]  \n",
      "- Persimmon monaka (persimmon-and-yuzu sweet) [2]  \n",
      "\n",
      "[1][2]\n",
      "\n",
      "Sources:\n",
      "- [1] https://spejapa-excursion.com/blog/b-70.html  \n",
      "- [2] https://livejapan.com/en/in-kansai/in-pref-nara/in-nara_ikoma_tenri/article-a2000428/\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Chain: Tavily -> format results\n",
    "context_chain = tavily_search | format_tavily_results\n",
    "\n",
    "prompt_text = \"\"\"\n",
    "Answer the user's question based only on the \"Knowledge\" below.\n",
    "Do not guess information that is not written in the Knowledge; instead, respond with \"I don't know from the provided knowledge.\"\n",
    "If possible, append the source numbers you referenced at the end of your answer (e.g., [1][2]).\n",
    "Finally, list the source numbers and URLs as bullet points.\n",
    "\n",
    "# Knowledge:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt_text),\n",
    "    (\"human\", \"Question: {question}\"),\n",
    "])\n",
    "\n",
    "# Create the model\n",
    "model = ChatOpenAI(model=MODEL_NAME)\n",
    "\n",
    "my_chain = (\n",
    "    {\"context\": context_chain,\n",
    "     \"question\": RunnablePassthrough()}\n",
    "    | prompt | model | str_output_parser\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "response = my_chain.invoke(\"What are some well-known souvenirs from Nara Prefecture?\")\n",
    "\n",
    "# Display the result\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b9686b",
   "metadata": {},
   "source": [
    "## 7. Conditional Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70a9d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables.router import RouterRunnable\n",
    "from pydantic import BaseModel, Field  # For defining structured data\n",
    "\n",
    "# Class definition for decision logic\n",
    "class SearchDecision(BaseModel):\n",
    "    \"\"\"A model for determining whether a web search is needed.\"\"\"\n",
    "    needs_search: bool = Field(\n",
    "        description=\"True if a web search is required, False if it is not.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94842a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A chain to determine whether a web search is needed\n",
    "needs_search_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{question}\\n\\nDo you need to perform a web search to answer this question?\")\n",
    "])\n",
    "\n",
    "needs_search_chain = (\n",
    "    needs_search_prompt\n",
    "    | model.with_structured_output(SearchDecision)\n",
    "    | (lambda x: \"search\" if x.needs_search else \"no_search\")  # Convert the decision into a routing key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae40443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain that performs the search\n",
    "context_chain = tavily_search | format_tavily_results\n",
    "\n",
    "prompt_text = \"\"\"\n",
    "Answer the user's question based only on the \"Knowledge\" below.\n",
    "Do not guess information that is not written in the Knowledge; instead, respond with \"I don't know from the provided knowledge.\"\n",
    "If possible, append the source numbers you referenced at the end of your answer (e.g., [1][2]).\n",
    "Finally, list the source numbers and URLs as bullet points.\n",
    "\n",
    "# Knowledge:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "search_answer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt_text),\n",
    "    (\"human\", \"Question: {question}\"),\n",
    "])\n",
    "\n",
    "search_chain = (\n",
    "    {\"context\": context_chain,\n",
    "     \"question\": RunnablePassthrough()}\n",
    "    | search_answer_prompt | model | str_output_parser\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f15814af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain that answers without performing a search\n",
    "no_search_answer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{question}\\n\\nPlease answer the question above.\")\n",
    "])\n",
    "\n",
    "no_search_chain = (\n",
    "    no_search_answer_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93590eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Branching with RouterRunnable\n",
    "# Execute the Runnable corresponding to the given key\n",
    "router = RouterRunnable(\n",
    "    runnables={\n",
    "        \"search\": search_chain,\n",
    "        \"no_search\": no_search_chain,\n",
    "    }\n",
    ")\n",
    "\n",
    "# RouterRunnable expects input in the form {\"key\": \"...\", \"input\": ...}\n",
    "final_chain = (\n",
    "    {\"key\": needs_search_chain, \"input\": RunnablePassthrough()}\n",
    "    | router\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c21ed3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Run: What is the price of the iPhone 16e? ---\n",
      "The iPhone 16e starts at $599 USD. [1][2]\n",
      "\n",
      "Sources:\n",
      "- [1] https://prices.appleinsider.com/iphone-16e\n",
      "- [2] https://www.facebook.com/cnet/videos/iphone-16e-review/4161070920885616/\n",
      "\n",
      "--- Run: What is 1+1? ---\n",
      "1 + 1 = 2.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Run: What is the price of the iPhone 16e? ---\")\n",
    "# needs_search_chain returns \"search\" -> search_chain is executed\n",
    "print(final_chain.invoke(\"What is the price of the iPhone 16e?\"))\n",
    "\n",
    "print(\"\\n--- Run: What is 1+1? ---\")\n",
    "# needs_search_chain returns \"no_search\" -> no_search_chain is executed\n",
    "print(final_chain.invoke(\"What is 1+1?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440427a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
