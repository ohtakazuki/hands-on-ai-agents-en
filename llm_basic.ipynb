{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eaa3aa5",
   "metadata": {},
   "source": [
    "# LLM Programming Basics\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec02140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create an OpenAI API client\n",
    "client = OpenAI()\n",
    "\n",
    "# Model name\n",
    "MODEL_NAME = \"gpt-5-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40159911",
   "metadata": {},
   "source": [
    "## A Basic API Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94979a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-Cx6bG1cs7TQjbUSR5Z4joRH3OHqTI\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"- Purpose and scope: define what you want the model to do and what it should not do. Pick a model whose strengths match the task (creative text, summarization, code, classification, dialog).\\n\\n- Safety and ethics: assess risks of harmful, offensive, or deceptive outputs. Add guardrails (filters, safety classifiers, system prompts) and a human-in-the-loop for risky decisions.\\n\\n- Accuracy and hallucination: LMs can invent facts or be confidently wrong. Always verify factual claims (use retrieval-augmented generation or external sources, add citations, or require human verification for high-stakes outputs).\\n\\n- Bias and fairness: be aware of dataset and model biases that can produce unfair or prejudiced content. Test for disparate impacts and apply debiasing, filtering, or controlled output policies as needed.\\n\\n- Privacy and data protection: avoid sending sensitive personal data unless you have appropriate consent and protections. Use data minimization, encryption in transit and at rest, and clear retention policies.\\n\\n- Security and adversarial robustness: consider prompt injection, input manipulation, and other attack vectors. Sanitize inputs, restrict code execution, and validate outputs used for automated actions.\\n\\n- Explainability and transparency: be clear to users that content is model-generated; provide confidence indicators, provenance, and a summary of sources when possible.\\n\\n- Prompt engineering and configuration: craft clear instructions, use examples (few-shot), constrain temperature/top-p for determinism when required, and tune system messages for desired tone and behavior.\\n\\n- Grounding and retrieval: for factual/realtime needs, combine the model with up-to-date retrieval, databases, or APIs rather than relying solely on the model’s internal knowledge.\\n\\n- Human oversight and escalation: define thresholds for when to escalate to human reviewers (safety, legal, high-value decisions) and provide a feedback loop to improve the system.\\n\\n- Evaluation and monitoring: continuously test for quality, bias, drift, latency, and user satisfaction. Log interactions, track metrics, and run adversarial tests.\\n\\n- Legal and compliance: check intellectual property, copyright, regulatory requirements (healthcare, finance, minors), and licensing for both the model and input/output data.\\n\\n- Cost, latency, and scalability: account for inference cost, throughput, response time, and infrastructure needs. Consider model size, batching, caching, and rate limits.\\n\\n- Versioning and reproducibility: record model versions, prompts, and hyperparameters so outputs can be traced and behavior reproduced or audited.\\n\\n- User experience and trust: design helpful error-handling, disclaimers, and easy ways for users to correct or contest outputs. Avoid overclaiming the model’s capabilities.\\n\\n- Maintenance and updates: plan for retraining, re-evaluating, and updating models and prompt templates as requirements, data, and risks evolve.\\n\\nUse these considerations to create policies, technical controls, and operational practices appropriate to your domain and risk level.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1768202758,\n",
      "  \"model\": \"gpt-5-mini-2025-08-07\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 911,\n",
      "    \"prompt_tokens\": 15,\n",
      "    \"total_tokens\": 926,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 320,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Set the message\n",
    "message = \"Key considerations when using a language model include:\"\n",
    "\n",
    "# Send a request to the API\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a536684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Purpose and scope: define what you want the model to do and what it should not do. Pick a model whose strengths match the task (creative text, summarization, code, classification, dialog).\n",
      "\n",
      "- Safety and ethics: assess risks of harmful, offensive, or deceptive outputs. Add guardrails (filters, safety classifiers, system prompts) and a human-in-the-loop for risky decisions.\n",
      "\n",
      "- Accuracy and hallucination: LMs can invent facts or be confidently wrong. Always verify factual claims (use retrieval-augmented generation or external sources, add citations, or require human verification for high-stakes outputs).\n",
      "\n",
      "- Bias and fairness: be aware of dataset and model biases that can produce unfair or prejudiced content. Test for disparate impacts and apply debiasing, filtering, or controlled output policies as needed.\n",
      "\n",
      "- Privacy and data protection: avoid sending sensitive personal data unless you have appropriate consent and protections. Use data minimization, encryption in transit and at rest, and clear retention policies.\n",
      "\n",
      "- Security and adversarial robustness: consider prompt injection, input manipulation, and other attack vectors. Sanitize inputs, restrict code execution, and validate outputs used for automated actions.\n",
      "\n",
      "- Explainability and transparency: be clear to users that content is model-generated; provide confidence indicators, provenance, and a summary of sources when possible.\n",
      "\n",
      "- Prompt engineering and configuration: craft clear instructions, use examples (few-shot), constrain temperature/top-p for determinism when required, and tune system messages for desired tone and behavior.\n",
      "\n",
      "- Grounding and retrieval: for factual/realtime needs, combine the model with up-to-date retrieval, databases, or APIs rather than relying solely on the model’s internal knowledge.\n",
      "\n",
      "- Human oversight and escalation: define thresholds for when to escalate to human reviewers (safety, legal, high-value decisions) and provide a feedback loop to improve the system.\n",
      "\n",
      "- Evaluation and monitoring: continuously test for quality, bias, drift, latency, and user satisfaction. Log interactions, track metrics, and run adversarial tests.\n",
      "\n",
      "- Legal and compliance: check intellectual property, copyright, regulatory requirements (healthcare, finance, minors), and licensing for both the model and input/output data.\n",
      "\n",
      "- Cost, latency, and scalability: account for inference cost, throughput, response time, and infrastructure needs. Consider model size, batching, caching, and rate limits.\n",
      "\n",
      "- Versioning and reproducibility: record model versions, prompts, and hyperparameters so outputs can be traced and behavior reproduced or audited.\n",
      "\n",
      "- User experience and trust: design helpful error-handling, disclaimers, and easy ways for users to correct or contest outputs. Avoid overclaiming the model’s capabilities.\n",
      "\n",
      "- Maintenance and updates: plan for retraining, re-evaluating, and updating models and prompt templates as requirements, data, and risks evolve.\n",
      "\n",
      "Use these considerations to create policies, technical controls, and operational practices appropriate to your domain and risk level.\n"
     ]
    }
   ],
   "source": [
    "# Print the model's reply\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d82416",
   "metadata": {},
   "source": [
    "## Setting Roles and Assumptions: `messages.role`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e08a9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a practical, repeatable marketing strategy you can use to launch a new product. It’s organized into phases (pre-launch, launch, post-launch), includes channels and tactics for both B2C and B2B, a sample 90-day timeline, suggested budget allocation ranges, and the KPIs you should track. Tell me your product type, target customers, budget and timeline and I’ll tailor it.\n",
      "\n",
      "Core principles\n",
      "- Start with clarity: define target audience, primary pain point solved, key differentiator, and a single measurable launch objective (e.g., X signups, Y revenue, Z trials).\n",
      "- Build a funnel and metrics before you spend: awareness → consideration → acquisition → activation → retention → referral (AARRR).\n",
      "- Validate with a small test/beta before scaling ad spend.\n",
      "- Use data to iterate weekly.\n",
      "\n",
      "High-level phased plan\n",
      "1. Discovery (1–3 weeks)\n",
      "- Customer & competitor research: interviews, surveys, keyword research, competitive messaging audit.\n",
      "- Define buyer personas, JTBD (jobs-to-be-done), primary value proposition and positioning statement.\n",
      "- Choose launch objective(s) and target KPIs (CAC, conversion rate, activation rate).\n",
      "\n",
      "2. Pre-launch (4–8 weeks)\n",
      "- Create core assets: landing page with email capture, product explainer (video or 1-pager), hero messaging, press kit, demo script.\n",
      "- Content plan: blog posts, SEO pages, social content, email nurture sequence.\n",
      "- Build credibility: early access/beta invites, case studies or testimonials (even pilot customers), influencer outreach.\n",
      "- Set up analytics and tracking: Google Analytics/GA4, event tracking (Mixpanel/Amplitude), conversion pixels, UTM structure, dashboard.\n",
      "- Seeding: soft outreach to partners, press, influencers, and a small paid test campaign to validate messaging.\n",
      "\n",
      "3. Launch (day 0 → 2 weeks)\n",
      "- Execute coordinated push: send launch emails, publish product page, distribute press release + targeted outreach, push social posts and ads, activate influencers.\n",
      "- Tactical plays: launch webinar or live demo, limited-time offer, referral incentive for early adopters, paid social + search scaled from winning creatives.\n",
      "- Capture feedback (support, live chat, NPS survey) and fix critical friction fast.\n",
      "\n",
      "4. Post-launch optimization & scale (weeks 3–12+)\n",
      "- Analyze funnel drop-offs, run A/B tests on landing pages/ad creatives/email copy/pricing.\n",
      "- Ramp or reallocate spend to best performing channels.\n",
      "- Focus on activation and retention: onboarding flows, product tutorials, in-app messaging, customer success outreach.\n",
      "- Grow referrals & partnerships, produce case studies and PR follow-ups.\n",
      "\n",
      "Channel and tactic recommendations (pick according to B2C vs B2B)\n",
      "- Website & landing page: central conversion asset. Clear headline, 1–2 key benefits, CTA, social proof.\n",
      "- SEO & content: target long-tail keywords for organic acquisition; 3–6 pillar blog posts pre-launch.\n",
      "- Email marketing: list building pre-launch, segmented nurture sequences, onboarding series after signup.\n",
      "- Paid ads: search ads for intent, social ads (Facebook/Instagram/TikTok/LinkedIn depending on audience). Start small + test creatives.\n",
      "- PR & media outreach: targeted journalists, niche blogs, product directories, HARO.\n",
      "- Influencers & creators: micro-influencers for authenticity; product seeding for reviews/demos.\n",
      "- Product-led tactics: free trial, freemium plan, live demos, in-product prompts.\n",
      "- Partnerships & affiliates: co-marketing with complementary brands or resellers.\n",
      "- Events & webinars: demos, Q&A sessions, virtual launch event for B2B or enthusiast B2C markets.\n",
      "- Referral & incentives: double-sided rewards to encourage sharing.\n",
      "\n",
      "Sample 90-day launch timeline (high level)\n",
      "- Week -6 to -4: Research, messaging, landing page, beta signups, press list, content calendar.\n",
      "- Week -3 to -1: Beta/test group, collect testimonials, finalize creatives, set up tracking, run small paid tests.\n",
      "- Launch week: Press outreach, email blast, launch event/webinar, scale winning paid creatives, influencer posts go live.\n",
      "- Weeks 2–4: Monitor KPIs, fix onboarding friction, publish case studies, retarget visitors with ads.\n",
      "- Weeks 5–12: Scale channels that show ROI, expand content/SEO, deepen partner outreach, run retention experiments (email onboarding, in-app guides).\n",
      "\n",
      "Suggested budget allocation (flexible by product & goals)\n",
      "- Creative & content (assets, landing page, video): 15–25%\n",
      "- Paid acquisition (ads, search/social): 30–50% (start low, scale to top performers)\n",
      "- PR & influencer outreach: 10–20%\n",
      "- Tools & analytics (tracking, CRO tools): 5–10%\n",
      "- Events/partnerships/referral incentives: 5–15%\n",
      "\n",
      "KPIs & dashboard (what to track initially)\n",
      "- Awareness: impressions, reach, website traffic\n",
      "- Consideration: CTR, landing page conversion rate (email signups, trials)\n",
      "- Acquisition: number of customers/users acquired, CAC (by channel)\n",
      "- Activation: % users who complete key action (first purchase, first meaningful use within X days)\n",
      "- Revenue: MRR/ARR, ARPU, average order value\n",
      "- Retention: churn rate, day-7/day-30 retention\n",
      "- Referral/virality: % of customers who refer, viral coefficient\n",
      "\n",
      "Testing & optimization checklist\n",
      "- Run at least 3 creatives + 2 audiences per channel to identify winners.\n",
      "- A/B test landing page headline, CTA, and hero image first.\n",
      "- Optimize onboarding steps to reduce time-to-value.\n",
      "- Weekly experiment review: pause poor performers, reinvest in winners.\n",
      "\n",
      "Messaging & positioning tips\n",
      "- Lead with problem and tangible outcome (not features).\n",
      "- Use one clear headline + 2 secondary bullets describing benefit + proof (social proof/data).\n",
      "- For B2B emphasize ROI, time saved, risk reduction; for B2C emphasize emotional benefit and immediate value.\n",
      "\n",
      "Quick template for a launch play (example)\n",
      "- Offer: 14-day free trial + 20% off first 3 months for early adopters.\n",
      "- Lead magnet: downloadable guide + gated webinar.\n",
      "- Paid: Search ads for intent keywords, social ads to lookalike audiences based on pilot customers.\n",
      "- Outreach: Email to existing list + targeted PR pitches to niche publications.\n",
      "- Follow-up: Automated onboarding email sequence + in-app checklist for activation.\n",
      "\n",
      "Common pitfalls to avoid\n",
      "- Launching without measurable goals or tracking.\n",
      "- Spreading spend across too many channels before validating one or two.\n",
      "- Ignoring onboarding (acquisition without activation wastes money).\n",
      "- Delaying customer feedback loops—fix early friction immediately.\n",
      "\n",
      "If you want a tailored plan, please tell me:\n",
      "- Product type and price point (B2B or B2C; SaaS, physical product, marketplace, etc.)\n",
      "- Target customer profiles and geographies\n",
      "- Launch timeline and total marketing budget\n",
      "- Primary goal (awareness, signups, revenue, enterprise deals)\n",
      "\n",
      "I’ll build a specific 8–12 week launch plan, recommended channels, sample creatives, and a projected budget/CAC estimate.\n"
     ]
    }
   ],
   "source": [
    "# Set roles and assumptions\n",
    "role = \"You are a business consultant with expertise in marketing. Your role is to help companies grow by providing practical, effective marketing strategies.\"\n",
    "\n",
    "# Set the user message\n",
    "message = \"Could you suggest an effective marketing strategy for launching a new product?\"\n",
    "\n",
    "# Send a request to the API\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": role},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print the model's reply\n",
    "print(response.choices[0].message.content.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e21a50",
   "metadata": {},
   "source": [
    "## Output Diversity: `temperature`, `top_p`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62162688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Japan is widely regarded as an appealing destination for various reasons, appealing to diverse interests, including visitors, potential expatriates, and travelers. Here are some of the primary factors that contribute to Japan's allure:\n",
      "\n",
      "1. **Rich Culture and Heritage**: Japan boasts a unique blending of traditional and modern culture. It is home to ancient temples, shrines, and historic cities, such as Kyoto and Nara, alongside ultra-modern architecture and technology in cities like Tokyo.\n",
      "\n",
      "2. **Delicious Cuisine**\n",
      "--------------------\n",
      "Japan appeals to many travelers and enthusiasts for a variety of reasons, including its rich cultural heritage, technological advancements, and breathtaking landscapes, amongst others. Here are some factors that contribute to Japan's allure:\n",
      "\n",
      "1. **Cultural Heritage**: Japan boasts a long and vibrant history with traditional arts such as tea ceremonies, calligraphy, and ikebana (flower arranging). UNESCO World Heritage sites, traditional festivals, and ancient temples and shrines add to its cultural depth.\n",
      "\n",
      "2. **Modernity &\n",
      "--------------------\n",
      "Japan is widely appealing for a variety of reasons, blending rich history, unique culture, technological advancement, and breathtaking landscapes. Here are several factors that contribute to its allure:\n",
      "\n",
      "1. **Cultural Richness**: Japan has a history spanning thousands of years that includes samurai, traditional tea ceremonies, sumo wrestling, and geisha. Its festivals (matsuri), with vibrant costumes and traditional performances, provide a glimpse into its lively and enduring customs.\n",
      "\n",
      "2. **Cuisine**: Japanese food\n"
     ]
    }
   ],
   "source": [
    "# Change the model\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "# Output diversity\n",
    "message = \"Tell me what makes Japan appealing.\"\n",
    "\n",
    "# Send a request to the API\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    temperature=1.4,\n",
    "    n=3, # get 3 answers\n",
    "    max_completion_tokens=100 # limit output length\n",
    ")\n",
    "\n",
    "# Print results (compare multiple answers)\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice.message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efea9bd",
   "metadata": {},
   "source": [
    "## Reducing Repeated Words (Tokens): `presence_penalty`, `frequency_penalty`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f3da07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "1. able  \n",
      "2. acid  \n",
      "3. aged  \n",
      "4. also  \n",
      "5. arch  \n",
      "6. army  \n",
      "7. away  \n",
      "8. area  \n",
      "9. ant  \n",
      "10. ape  \n",
      "11. ask  \n",
      "12. ax  \n",
      "13. art  \n",
      "14. air  \n",
      "15. ant  \n",
      "16. arch  \n",
      "17. arch  \n",
      "18. add  \n",
      "19. ache  \n",
      "20. akin\n"
     ]
    }
   ],
   "source": [
    "# Change the model\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "# Output diversity\n",
    "message = \"List 20 standard English dictionary words that start with 'a' and are at most five letters long. Output only the words.\"\n",
    "\n",
    "# Send a request to the API\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    presence_penalty=-2.0\n",
    ")\n",
    "\n",
    "# Print results (compare multiple answers)\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice.message.content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c84e6d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "1. Apple  \n",
      "2. Ants  \n",
      "3. Area  \n",
      "4. Arch  \n",
      "5. Away  \n",
      "6. Aisle  \n",
      "7. Acid  \n",
      "8. Asks  \n",
      "9. Able  \n",
      "10. Army  \n",
      "11. Alms  \n",
      "12. Airy  \n",
      "13. Atom  \n",
      "14. Aged  \n",
      "15. Axis  \n",
      "16. Along  \n",
      "17. Anger  \n",
      "18. Art  \n",
      "19. Awe  \n",
      "20. Axes\n"
     ]
    }
   ],
   "source": [
    "# Change the model\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "# Output diversity\n",
    "message = \"List 20 standard English dictionary words that start with 'a' and are at most five letters long. Output only the words.\"\n",
    "\n",
    "# Send a request to the API\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    presence_penalty=2.0\n",
    ")\n",
    "\n",
    "# Print results (compare multiple answers)\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice.message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9da7d02",
   "metadata": {},
   "source": [
    "## Token selection preference: `logit_bias`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7af2acaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_count=2\n",
      "tokens=[13225, 0]\n"
     ]
    }
   ],
   "source": [
    "# Change the model\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "import tiktoken\n",
    "from tiktoken.core import Encoding\n",
    "\n",
    "# Get a tokenizer for the specific OpenAI model\n",
    "encoding: Encoding = tiktoken.encoding_for_model(MODEL_NAME) # o200k_base\n",
    "\n",
    "# Convert text to a list of token IDs\n",
    "tokens = encoding.encode(\"Hello!\")\n",
    "tokens_count = len(tokens)\n",
    "\n",
    "# Print token length and token IDs\n",
    "print(f\"{tokens_count=}\")\n",
    "print(f\"{tokens=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "725b8f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "B: Hey, A! I didn't expect to run into you here. How have you been? \n",
      "\n",
      "A: I've been doing well! Just busy with work and stuff. How about you?\n",
      "\n",
      "B: Same here! Work has been keeping me on my toes. But I managed to take some time off last weekend to recharge.\n",
      "\n",
      "A: That sounds nice! What did you do with your time off?\n",
      "\n",
      "B: I went hiking! The weather was perfect, and the views were amazing. We should\n",
      "--------------------\n",
      "B: Hey! I didn't expect to run into you here. How have you been? \n",
      "\n",
      "A: I've been good! Just busy with work and trying to catch up on some hobbies. How about you? \n",
      "\n",
      "B: Same here! Work has been pretty hectic lately, but I'm trying to find time to relax. Have you been up to anything fun? \n",
      "\n",
      "A: I actually started painting! It’s been a great way to unwind. \n",
      "\n",
      "B: That sounds amazing! What kind of things\n",
      "--------------------\n",
      "B: Hey! Yeah, it's me. How have you been? \n",
      "\n",
      "A: I've been good! Just busy with work, you know how it is. What about you? \n",
      "\n",
      "B: Same! The workload seems to be piling up, but I managed to sneak in some time for a hike last weekend. \n",
      "\n",
      "A: That sounds nice! Where did you go? \n",
      "\n",
      "B: I went to the Blue Ridge Trail. The views were stunning! You should join me next time! \n",
      "\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "# Control token selection\n",
    "message = \"\"\"\n",
    "Please write a conversation between Person A and Person B.\n",
    "A: Oh, it's you, B.\n",
    "B:\n",
    "\"\"\"\n",
    "\n",
    "# Send a request to the API\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    max_completion_tokens=100,\n",
    "    n=3,\n",
    "    logit_bias={13225:8, 0:8}\n",
    ")\n",
    "\n",
    "# Print results\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice.message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2af059",
   "metadata": {},
   "source": [
    "## Streaming Output: `stream`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f194a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are key considerations when using a language model, grouped for clarity. Each item includes a brief note or mitigation you can apply.\n",
      "\n",
      "Performance & limitations\n",
      "- Capabilities and limits: know what the model can and cannot do (reasoning, knowledge cutoff, token limits). Mitigation: design tasks within strengths; verify output.\n",
      "- Hallucinations and factual errors: models may invent facts or confident-sounding but wrong answers. Mitigation: cross-check with trusted sources, add retrieval/grounding, require citations.\n",
      "- Ambiguity and context sensitivity: outputs depend heavily on prompts and context window. Mitigation: supply clear, complete prompts and necessary context; include examples.\n",
      "\n",
      "Safety, bias and fairness\n",
      "- Bias and harmful content: outputs can reflect training data biases or produce offensive content. Mitigation: filter outputs, use safety layers, and test with diverse inputs.\n",
      "- Misuse potential: models can be used for spam, social engineering, fraud, or generating disinformation. Mitigation: restrict access, enforce usage policies, monitor behavior.\n",
      "\n",
      "Security & adversarial risks\n",
      "- Prompt injection and jailbreaks: malicious inputs can override instructions or reveal system prompts. Mitigation: input sanitization, strict system prompts, output filtering, separate sensitive logic from model.\n",
      "- Data poisoning and model theft: training data or model parameters can be attacked. Mitigation: secure training pipelines, access controls, and watermarking where applicable.\n",
      "\n",
      "Privacy & data governance\n",
      "- Sensitive data exposure: models may inadvertently reveal private/training data or retain user inputs. Mitigation: avoid sending sensitive data, apply anonymization, use data retention policies, and opt for private/on-prem deployments if needed.\n",
      "- Compliance and legal constraints: consider GDPR, HIPAA, export control, and contract obligations. Mitigation: conduct legal review and implement appropriate controls.\n",
      "\n",
      "Quality assurance & evaluation\n",
      "- Evaluation and testing: measure accuracy, coherence, safety, and user satisfaction with realistic datasets and adversarial tests. Mitigation: automated tests + human review.\n",
      "- Human-in-the-loop: use human oversight for high-stakes decisions and for labeling/correcting training data.\n",
      "\n",
      "User experience & usability\n",
      "- Explainability and transparency: users should understand the model’s role, uncertainty, and limitations. Mitigation: provide confidence indicators, provenance, and clear disclaimers.\n",
      "- Prompt engineering and UX: good prompts greatly affect outcomes. Mitigation: create templates, guardrails, and examples; allow users to give feedback.\n",
      "\n",
      "Operational & cost considerations\n",
      "- Latency and scalability: real-time use may need lower-latency or smaller models; batch tasks scale differently. Mitigation: select models and infrastructure to match SLAs.\n",
      "- Cost and token usage: heavier prompts and larger models cost more. Mitigation: optimize prompts, cache frequent responses, and use smaller models when acceptable.\n",
      "\n",
      "Maintenance & governance\n",
      "- Model updates and drift: performance can change as distributions shift or models are updated. Mitigation: monitor, retrain/refresh, and version-control models.\n",
      "- Auditability and logging: keep logs for debugging, compliance, and incident analysis, while protecting privacy. Mitigation: redaction and access controls.\n",
      "\n",
      "Ethics, societal impact & accountability\n",
      "- Impact assessment: consider social and business impacts before deployment (e.g., job displacement, misinformation). Mitigation: stakeholder review and risk assessment.\n",
      "- Clear ownership and responsibility: define who is accountable for outputs and remediation.\n",
      "\n",
      "If you tell me the specific use case (customer support, coding assistant, research summarization, etc.), I can tailor this list with prioritized actions and concrete mitigations."
     ]
    }
   ],
   "source": [
    "# Model name\n",
    "MODEL_NAME = \"gpt-5-mini\"\n",
    "\n",
    "# Set the message\n",
    "message = \"Key considerations when using a language model include:\"\n",
    "\n",
    "# Send a request to the API\n",
    "stream = client.chat.completions.create(\n",
    "   model=MODEL_NAME,\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": message},\n",
    "   ],\n",
    "   stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "   if chunk.choices:\n",
    "       if chunk.choices[0].delta.content is not None:\n",
    "           print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac9127",
   "metadata": {},
   "source": [
    "## Building a Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4bd1f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:What does “zunda” in “Zundamon” mean?\n",
      "\"Zunda\" (ずんだ) is a sweet paste made from mashed edamame (young green soybeans). It's a specialty of Sendai and Miyagi Prefecture in Japan, commonly used as a topping for mochi (zunda mochi) or in sweets and desserts. The paste is bright green and flavored with sugar and a little salt.\n",
      "\n",
      "In \"Zundamon,\" the name is a compound of zunda + mon (モン), where \"mon\" is a common suffix for characters/monsters/mascots (as in \"monster\" or friendly character names). So \"Zundamon\" essentially means a character or mascot based on zunda.\n",
      "Question:Which prefecture is it from?\n",
      "Zunda is from Miyagi Prefecture — especially associated with Sendai city in the Tōhoku region. It's famous there as zunda-mochi and in local sweets.\n",
      "Question:What was my first question?\n",
      "Your first question was: \"What does 'zunda' in 'Zundamon' mean?\"\n",
      "\n",
      "---Thank you for using this! ---\n"
     ]
    }
   ],
   "source": [
    "# A list to store messages\n",
    "messages = []\n",
    "\n",
    "while True:\n",
    "   # Read a question from the user\n",
    "   message = input(\"Enter a message:\")\n",
    "   # Exit if nothing was entered\n",
    "   if message.strip()==\"\":\n",
    "       break\n",
    "   print(f\"Question:{message}\")\n",
    "\n",
    "   # Add the user message\n",
    "   messages.append({\"role\": \"user\", \"content\": message.strip()})\n",
    "\n",
    "   # Send a request to the API\n",
    "   stream = client.chat.completions.create(\n",
    "       model=MODEL_NAME,\n",
    "       messages=messages,\n",
    "       stream=True,\n",
    "   )\n",
    "\n",
    "   # Print the model's reply\n",
    "   response_message = \"\"\n",
    "   for chunk in stream:\n",
    "       if chunk.choices:\n",
    "           delta = chunk.choices[0].delta.content\n",
    "           if delta is not None:\n",
    "               response_message += delta\n",
    "               print(delta, end='')\n",
    "   print()\n",
    "\n",
    "   # Add the assistant message\n",
    "   messages.append({\"role\": \"assistant\", \"content\": response_message})\n",
    "\n",
    "   # If turns exceed 8, drop the oldest 1 round-trip (user + assistant)\n",
    "   if len(messages) > 8:\n",
    "       messages = messages[2:]\n",
    "\n",
    "print(\"\\n---Thank you for using this! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc52f144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
